{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "display_name": "IPython (Python 2)",
   "language": "python",
   "name": "python2"
  },
  "name": "",
  "signature": "sha256:ec9f8e859724befab795cfffb62fe8196b0a1c2b24b5380e7b561efc3fa45961"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "# Now we are ready to import Spark Modules\n",
      "try:\n",
      "    from pyspark import SparkContext\n",
      "    from pyspark import SparkConf\n",
      "\n",
      "except ImportError as e:\n",
      "    print (\"Error importing Spark Modules\", e)\n",
      "    sys.exit(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc = SparkContext()\n",
      "small_ints = sc.parallelize(range(10))\n",
      "\n",
      "print (\"add up 0 to 10 via reduce\", small_ints.reduce(lambda x, y: x+ y))\n",
      "print (\"double 0 to 10 (using collect): \", small_ints.map(lambda x: 2*x).collect())\n",
      "print (\"double 0 to 10 (using take): \", small_ints.map(lambda x: 2*x).take(100))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('add up 0 to 10 via reduce', 45)\n",
        "('double 0 to 10 (using collect): ', [0, 2, 4, 6, 8, 10, 12, 14, 16, 18])\n",
        "('double 0 to 10 (using take): ', [0, 2, 4, 6, 8, 10, 12, 14, 16, 18])\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}